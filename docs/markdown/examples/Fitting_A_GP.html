

<!DOCTYPE html>
<!--[if IE 8]><html class="no-js lt-ie9" lang="en" > <![endif]-->
<!--[if gt IE 8]><!--> <html class="no-js" lang="en" > <!--<![endif]-->
<head>
  <meta charset="utf-8">
  
  <meta name="viewport" content="width=device-width, initial-scale=1.0">
  
  <title>Fitting A Gaussian Process &mdash; Squidward  documentation</title>
  

  
  
  
  

  
  <script type="text/javascript" src="../../_static/js/modernizr.min.js"></script>
  
    
      <script type="text/javascript" id="documentation_options" data-url_root="../../" src="../../_static/documentation_options.js"></script>
        <script type="text/javascript" src="../../_static/jquery.js"></script>
        <script type="text/javascript" src="../../_static/underscore.js"></script>
        <script type="text/javascript" src="../../_static/doctools.js"></script>
        <script type="text/javascript" src="../../_static/language_data.js"></script>
        <script async="async" type="text/javascript" src="https://cdnjs.cloudflare.com/ajax/libs/mathjax/2.7.5/latest.js?config=TeX-AMS-MML_HTMLorMML"></script>
        <script type="text/x-mathjax-config">MathJax.Hub.Config({"tex2jax": {"inlineMath": [["$", "$"], ["\\(", "\\)"]], "processEscapes": true, "ignoreClass": "document", "processClass": "math|output_area"}})</script>
    
    <script type="text/javascript" src="../../_static/js/theme.js"></script>

    

  
  <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" />
    <link rel="prev" title="An Introduction to Gaussian Processes Models" href="Intro_To_GP.html" /> 
</head>

<body class="wy-body-for-nav">

   
  <div class="wy-grid-for-nav">
    
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
          

          
            <a href="../../index.html" class="icon icon-home"> Squidward
          

          
          </a>

          
            
            
          

          
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>

          
        </div>

        <div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="main navigation">
          
            
            
              
            
            
              <p class="caption"><span class="caption-text">Squidward Overview:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../README.html">Squidward</a></li>
</ul>
<p class="caption"><span class="caption-text">Squidward Examples:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="Working_With_Kernels.html">Working with Kernels</a></li>
<li class="toctree-l1"><a class="reference internal" href="Regression.html">Gaussian Process Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="Heteroscedastic_GP.html">Heteroscedastic Gaussian Process Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="NonZero_Prior_Mean.html">Non-Zero Prior Mean for Gaussian Process Regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="Classification.html">Gaussian Process Classification</a></li>
</ul>
<p class="caption"><span class="caption-text">Gaussian Process Tutorials:</span></p>
<ul class="current">
<li class="toctree-l1"><a class="reference internal" href="Intro_To_GP.html">An Introduction to Gaussian Processes Models</a></li>
<li class="toctree-l1 current"><a class="current reference internal" href="#">Fitting A Gaussian Process</a><ul>
<li class="toctree-l2"><a class="reference internal" href="#Setting-Up-An-Example-Problem">Setting Up An Example Problem</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Maximum-Likelihood-Estimation">Maximum Likelihood Estimation</a></li>
<li class="toctree-l2"><a class="reference internal" href="#Inference">Inference</a></li>
</ul>
</li>
</ul>

            
          
        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap">

      
      <nav class="wy-nav-top" aria-label="top navigation">
        
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">Squidward</a>
        
      </nav>


      <div class="wy-nav-content">
        
        <div class="rst-content">
        
          















<div role="navigation" aria-label="breadcrumbs navigation">

  <ul class="wy-breadcrumbs">
    
      <li><a href="../../index.html">Docs</a> &raquo;</li>
        
      <li>Fitting A Gaussian Process</li>
    
    
      <li class="wy-breadcrumbs-aside">
        
            
            <a href="../../_sources/markdown/examples/Fitting_A_GP.ipynb.txt" rel="nofollow"> View page source</a>
          
        
      </li>
    
  </ul>

  
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
            
  
<style>
/* CSS for nbsphinx extension */

/* remove conflicting styling from Sphinx themes */
div.nbinput,
div.nbinput div.prompt,
div.nbinput div.input_area,
div.nbinput div[class*=highlight],
div.nbinput div[class*=highlight] pre,
div.nboutput,
div.nbinput div.prompt,
div.nbinput div.output_area,
div.nboutput div[class*=highlight],
div.nboutput div[class*=highlight] pre {
    background: none;
    border: none;
    padding: 0 0;
    margin: 0;
    box-shadow: none;
}

/* avoid gaps between output lines */
div.nboutput div[class*=highlight] pre {
    line-height: normal;
}

/* input/output containers */
div.nbinput,
div.nboutput {
    display: -webkit-flex;
    display: flex;
    align-items: flex-start;
    margin: 0;
    width: 100%;
}
@media (max-width: 540px) {
    div.nbinput,
    div.nboutput {
        flex-direction: column;
    }
}

/* input container */
div.nbinput {
    padding-top: 5px;
}

/* last container */
div.nblast {
    padding-bottom: 5px;
}

/* input prompt */
div.nbinput div.prompt pre {
    color: #307FC1;
}

/* output prompt */
div.nboutput div.prompt pre {
    color: #BF5B3D;
}

/* all prompts */
div.nbinput div.prompt,
div.nboutput div.prompt {
    min-width: 5ex;
    padding-top: 0.4em;
    padding-right: 0.4em;
    text-align: right;
    flex: 0;
}
@media (max-width: 540px) {
    div.nbinput div.prompt,
    div.nboutput div.prompt {
        text-align: left;
        padding: 0.4em;
    }
    div.nboutput div.prompt.empty {
        padding: 0;
    }
}

/* disable scrollbars on prompts */
div.nbinput div.prompt pre,
div.nboutput div.prompt pre {
    overflow: hidden;
}

/* input/output area */
div.nbinput div.input_area,
div.nboutput div.output_area {
    padding: 0.4em;
    -webkit-flex: 1;
    flex: 1;
    overflow: auto;
}
@media (max-width: 540px) {
    div.nbinput div.input_area,
    div.nboutput div.output_area {
        width: 100%;
    }
}

/* input area */
div.nbinput div.input_area {
    border: 1px solid #e0e0e0;
    border-radius: 2px;
    background: #f5f5f5;
}

/* override MathJax center alignment in output cells */
div.nboutput div[class*=MathJax] {
    text-align: left !important;
}

/* override sphinx.ext.imgmath center alignment in output cells */
div.nboutput div.math p {
    text-align: left;
}

/* standard error */
div.nboutput div.output_area.stderr {
    background: #fdd;
}

/* ANSI colors */
.ansi-black-fg { color: #3E424D; }
.ansi-black-bg { background-color: #3E424D; }
.ansi-black-intense-fg { color: #282C36; }
.ansi-black-intense-bg { background-color: #282C36; }
.ansi-red-fg { color: #E75C58; }
.ansi-red-bg { background-color: #E75C58; }
.ansi-red-intense-fg { color: #B22B31; }
.ansi-red-intense-bg { background-color: #B22B31; }
.ansi-green-fg { color: #00A250; }
.ansi-green-bg { background-color: #00A250; }
.ansi-green-intense-fg { color: #007427; }
.ansi-green-intense-bg { background-color: #007427; }
.ansi-yellow-fg { color: #DDB62B; }
.ansi-yellow-bg { background-color: #DDB62B; }
.ansi-yellow-intense-fg { color: #B27D12; }
.ansi-yellow-intense-bg { background-color: #B27D12; }
.ansi-blue-fg { color: #208FFB; }
.ansi-blue-bg { background-color: #208FFB; }
.ansi-blue-intense-fg { color: #0065CA; }
.ansi-blue-intense-bg { background-color: #0065CA; }
.ansi-magenta-fg { color: #D160C4; }
.ansi-magenta-bg { background-color: #D160C4; }
.ansi-magenta-intense-fg { color: #A03196; }
.ansi-magenta-intense-bg { background-color: #A03196; }
.ansi-cyan-fg { color: #60C6C8; }
.ansi-cyan-bg { background-color: #60C6C8; }
.ansi-cyan-intense-fg { color: #258F8F; }
.ansi-cyan-intense-bg { background-color: #258F8F; }
.ansi-white-fg { color: #C5C1B4; }
.ansi-white-bg { background-color: #C5C1B4; }
.ansi-white-intense-fg { color: #A1A6B2; }
.ansi-white-intense-bg { background-color: #A1A6B2; }

.ansi-default-inverse-fg { color: #FFFFFF; }
.ansi-default-inverse-bg { background-color: #000000; }

.ansi-bold { font-weight: bold; }
.ansi-underline { text-decoration: underline; }

/* Some additional styling taken form the Jupyter notebook CSS */
div.rendered_html table {
  border: none;
  border-collapse: collapse;
  border-spacing: 0;
  color: black;
  font-size: 12px;
  table-layout: fixed;
}
div.rendered_html thead {
  border-bottom: 1px solid black;
  vertical-align: bottom;
}
div.rendered_html tr,
div.rendered_html th,
div.rendered_html td {
  text-align: right;
  vertical-align: middle;
  padding: 0.5em 0.5em;
  line-height: normal;
  white-space: normal;
  max-width: none;
  border: none;
}
div.rendered_html th {
  font-weight: bold;
}
div.rendered_html tbody tr:nth-child(odd) {
  background: #f5f5f5;
}
div.rendered_html tbody tr:hover {
  background: rgba(66, 165, 245, 0.2);
}

/* CSS overrides for sphinx_rtd_theme */

/* 24px margin */
.nbinput.nblast,
.nboutput.nblast {
    margin-bottom: 19px;  /* padding has already 5px */
}

/* ... except between code cells! */
.nblast + .nbinput {
    margin-top: -19px;
}

.admonition > p:before {
    margin-right: 4px;  /* make room for the exclamation icon */
}

/* Fix math alignment, see https://github.com/rtfd/sphinx_rtd_theme/pull/686 */
.math {
    text-align: unset;
}
</style>
<div class="section" id="Fitting-A-Gaussian-Process">
<h1>Fitting A Gaussian Process<a class="headerlink" href="#Fitting-A-Gaussian-Process" title="Permalink to this headline">¶</a></h1>
<p>This notebook is a high level guide concerning the basic concepts to fit a Gaussian process model. Fitting Gaussian process models can be very complex and this notebook does not address the many nuances , tips, and tricks to fit such models well. This notebook merely covers the high level concepts.</p>
<p>It is assumed that the reader has an understanding of Bayesian</p>
<p>There are two philosophies for fitting GPs. The first is by far the easier (but less precise) which is maximum likelihood estimation (MLE). The second is to do inference (either Markov Chain Monte Carlo or Variational Inference). It is always faster to use MLE to fit the kernel parameters, but in practice this often leads to poorer fits for the GP. We walk through a simple example of each method here.</p>
<p>It may seem that I am using overly simplistic examples to explain the concepts in this notebook. I’m simply trying to reduce the complexity of the models being built so that students can focus on the fitting process.</p>
<div class="section" id="Setting-Up-An-Example-Problem">
<h2>Setting Up An Example Problem<a class="headerlink" href="#Setting-Up-An-Example-Problem" title="Permalink to this headline">¶</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[1]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># model with Squidward</span>
<span class="kn">from</span> <span class="nn">squidward.kernels</span> <span class="k">import</span> <span class="n">distance</span><span class="p">,</span> <span class="n">kernel_base</span>
<span class="kn">from</span> <span class="nn">squidward</span> <span class="k">import</span> <span class="n">gpr</span>

<span class="c1"># useful visualization functions</span>
<span class="kn">import</span> <span class="nn">gp_viz</span>

<span class="c1"># generate example data</span>
<span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>

<span class="c1"># plot example data</span>
<span class="kn">import</span> <span class="nn">matplotlib.pyplot</span> <span class="k">as</span> <span class="nn">plt</span>
<span class="kn">import</span> <span class="nn">seaborn</span> <span class="k">as</span> <span class="nn">sns</span>

<span class="kn">import</span> <span class="nn">warnings</span>
<span class="n">warnings</span><span class="o">.</span><span class="n">filterwarnings</span><span class="p">(</span><span class="s2">&quot;ignore&quot;</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[2]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># generate noisy samples for dataset</span>
<span class="n">samples</span> <span class="o">=</span> <span class="mi">100</span>

<span class="c1"># train data</span>
<span class="n">x_train</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">15</span><span class="p">,</span><span class="n">samples</span><span class="p">)</span>
<span class="n">noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">250</span><span class="p">,</span><span class="n">samples</span><span class="p">)</span>
<span class="n">y_train</span> <span class="o">=</span> <span class="mi">200</span> <span class="o">*</span> <span class="n">x_train</span> <span class="o">+</span> <span class="n">noise</span>

<span class="c1"># test data</span>
<span class="n">x_test</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">15</span><span class="p">,</span><span class="n">samples</span><span class="p">)</span>
<span class="n">noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">250</span><span class="p">,</span><span class="n">samples</span><span class="p">)</span>
<span class="n">y_test</span> <span class="o">=</span> <span class="mi">200</span> <span class="o">*</span> <span class="n">x_test</span> <span class="o">+</span> <span class="n">noise</span>

<span class="c1"># generate noiseless data to plot true mean</span>
<span class="n">x_true</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">15</span><span class="p">,</span><span class="mi">1000</span><span class="p">)</span>
<span class="n">y_true</span> <span class="o">=</span> <span class="mi">200</span> <span class="o">*</span> <span class="n">x_true</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[3]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># plot example dataset</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s1">&#39;1D GP Regression Example Dataset&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train Data&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;c&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Test Data&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">plot</span><span class="p">(</span><span class="n">x_true</span><span class="p">,</span><span class="n">y_true</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;True Mean of Data Generating Distribution&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/markdown_examples_Fitting_A_GP_4_0.png" src="../../_images/markdown_examples_Fitting_A_GP_4_0.png" />
</div>
</div>
</div>
<div class="section" id="Maximum-Likelihood-Estimation">
<h2>Maximum Likelihood Estimation<a class="headerlink" href="#Maximum-Likelihood-Estimation" title="Permalink to this headline">¶</a></h2>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[4]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># define loss function for optimizer</span>
<span class="k">def</span> <span class="nf">log_likelihood</span><span class="p">(</span><span class="n">args</span><span class="p">):</span>
    <span class="n">c</span><span class="p">,</span> <span class="n">var_b</span><span class="p">,</span> <span class="n">var_k</span><span class="p">,</span> <span class="n">var_l</span> <span class="o">=</span> <span class="n">args</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">args</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">args</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">args</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>

    <span class="n">d</span> <span class="o">=</span> <span class="n">distance</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">var_b</span><span class="p">,</span> <span class="n">var_k</span><span class="p">)</span>
    <span class="n">kernel</span> <span class="o">=</span> <span class="n">kernel_base</span><span class="o">.</span><span class="n">Kernel</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="s1">&#39;k1&#39;</span><span class="p">)</span>
    <span class="n">model</span> <span class="o">=</span> <span class="n">gpr</span><span class="o">.</span><span class="n">GaussianProcessInversion</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="n">kernel</span><span class="p">,</span> <span class="n">var_l</span><span class="o">=</span><span class="n">var_l</span><span class="p">,</span> <span class="n">show_warnings</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">float</span><span class="p">(</span><span class="s1">&#39;inf&#39;</span><span class="p">)</span>

    <span class="c1"># the prior / regularizing term</span>
    <span class="n">prior</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">args</span><span class="p">)</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

    <span class="c1"># log likelihood</span>
    <span class="n">log_likelihood</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="o">*</span><span class="n">y_train</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">inv_K</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span> <span class="o">+</span> <span class="o">-</span><span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">K</span><span class="p">))</span> <span class="o">+</span> <span class="n">prior</span>

    <span class="k">return</span> <span class="n">log_likelihood</span> <span class="o">+</span> <span class="n">prior</span>
</pre></div>
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[5]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="k">import</span> <span class="n">minimize</span>

<span class="c1"># initial starting parameter values</span>
<span class="n">initial_values</span> <span class="o">=</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">,</span> <span class="mi">10000</span><span class="p">,</span> <span class="mi">10000</span><span class="p">,</span> <span class="mi">250</span><span class="o">**</span><span class="mi">2</span><span class="p">]</span>

<span class="c1"># run optimizer</span>
<span class="n">result</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">log_likelihood</span><span class="p">,</span> <span class="n">initial_values</span><span class="p">,</span> <span class="n">bounds</span><span class="o">=</span><span class="p">((</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">),</span> <span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="kc">None</span><span class="p">)))</span>
</pre></div>
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[6]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="c1"># get optimizer results</span>
<span class="n">results</span> <span class="o">=</span> <span class="n">result</span><span class="o">.</span><span class="n">x</span><span class="o">.</span><span class="n">tolist</span><span class="p">()</span>
<span class="n">c</span><span class="p">,</span> <span class="n">var_b</span><span class="p">,</span> <span class="n">var_k</span><span class="p">,</span> <span class="n">var_l</span> <span class="o">=</span> <span class="n">results</span><span class="p">[</span><span class="mi">0</span><span class="p">],</span> <span class="n">results</span><span class="p">[</span><span class="mi">1</span><span class="p">],</span> <span class="n">results</span><span class="p">[</span><span class="mi">2</span><span class="p">],</span> <span class="n">results</span><span class="p">[</span><span class="mi">3</span><span class="p">]</span>

<span class="c1"># definine a GP based on optimal parameters</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">distance</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">var_b</span><span class="p">,</span> <span class="n">var_k</span><span class="p">)</span>
<span class="n">kernel</span> <span class="o">=</span> <span class="n">kernel_base</span><span class="o">.</span><span class="n">Kernel</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="s1">&#39;k1&#39;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">gpr</span><span class="o">.</span><span class="n">GaussianProcessInversion</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="n">kernel</span><span class="p">,</span> <span class="n">var_l</span><span class="o">=</span><span class="n">var_l</span><span class="p">,</span> <span class="n">show_warnings</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># generate data to plot posterior of model</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">15</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>

<span class="c1"># pull the parameters of the posterior distribution</span>
<span class="n">mean</span><span class="p">,</span> <span class="n">var</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">posterior_predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># plot posterior of model</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;GP Posterior Distribution&quot;</span><span class="p">)</span>
<span class="n">gp_viz</span><span class="o">.</span><span class="n">regression</span><span class="o">.</span><span class="n">plot_1d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">mean</span><span class="p">,</span><span class="n">var</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train Data&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;c&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Test Data&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># plot posterior predictive</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;GP Posterior Predictive&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>

    <span class="c1"># draw a sample from the posterior</span>
    <span class="n">posterior_sample</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">posterior_sample</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="c1"># add likelihood noise</span>
    <span class="n">liklihood_noise</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">var_l</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
    <span class="n">liklihood_noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">liklihood_noise</span><span class="p">)</span>
    <span class="n">posterior_predictive_sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">posterior_sample</span><span class="p">,</span> <span class="n">cov</span><span class="o">=</span><span class="n">liklihood_noise</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">posterior_predictive_sample</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;GP Posterior Predictive Sample&quot;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train Data&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;c&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Test Data&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/markdown_examples_Fitting_A_GP_8_0.png" src="../../_images/markdown_examples_Fitting_A_GP_8_0.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/markdown_examples_Fitting_A_GP_8_1.png" src="../../_images/markdown_examples_Fitting_A_GP_8_1.png" />
</div>
</div>
</div>
<div class="section" id="Inference">
<h2>Inference<a class="headerlink" href="#Inference" title="Permalink to this headline">¶</a></h2>
<p><strong>This is a toy example!</strong> While inference will provide the full posterior of the GP accounting for uncertainty in the kernel parameters, it is extremely costly computationally. Below I have an illustrative example of how one might go about setting up a metropolis sampler to find the posterior over kernel parameters. I don’t recommend using the code below for any actual modeling use case.</p>
<p>If you plan to do inference to find the posterior over kernel parameters for an actual model, I would recommend using a very efficient sampler ,such as a HMC or Slice sampler, to minimize the number of iterations required to get a valid posterior. Even better, you could use variational inference to find an approximation of the posterior over the kernel parameter.</p>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[7]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="kn">import</span> <span class="nn">progressbar</span>
<span class="kn">import</span> <span class="nn">scipy.stats</span> <span class="k">as</span> <span class="nn">st</span>

<span class="c1"># define loss function for optimizer</span>
<span class="k">def</span> <span class="nf">log_likelihood</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">var_b</span><span class="p">,</span> <span class="n">var_k</span><span class="p">,</span> <span class="n">var_l</span><span class="p">):</span>

    <span class="k">try</span><span class="p">:</span>
        <span class="n">d</span> <span class="o">=</span> <span class="n">distance</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">var_b</span><span class="p">,</span> <span class="n">var_k</span><span class="p">)</span>
        <span class="n">kernel</span> <span class="o">=</span> <span class="n">kernel_base</span><span class="o">.</span><span class="n">Kernel</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="s1">&#39;k1&#39;</span><span class="p">)</span>
        <span class="n">model</span> <span class="o">=</span> <span class="n">gpr</span><span class="o">.</span><span class="n">GaussianProcessInversion</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="n">kernel</span><span class="p">,</span> <span class="n">var_l</span><span class="o">=</span><span class="n">var_l</span><span class="p">,</span> <span class="n">show_warnings</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
        <span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>
    <span class="k">except</span><span class="p">:</span>
        <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">float</span><span class="p">(</span><span class="s1">&#39;-inf&#39;</span><span class="p">)</span>

    <span class="c1"># the prior / regularizing term</span>
    <span class="n">prior</span> <span class="o">=</span> <span class="n">st</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">)</span><span class="o">.</span><span class="n">logpdf</span><span class="p">(</span><span class="n">c</span><span class="p">)</span> <span class="o">+</span> \
            <span class="n">st</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="mi">200</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1000</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">logpdf</span><span class="p">(</span><span class="n">var_b</span><span class="p">)</span> <span class="o">+</span> \
            <span class="n">st</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="mi">200</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1000</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">logpdf</span><span class="p">(</span><span class="n">var_k</span><span class="p">)</span> <span class="o">+</span> \
            <span class="n">st</span><span class="o">.</span><span class="n">norm</span><span class="p">(</span><span class="mi">200</span><span class="o">**</span><span class="mi">2</span><span class="p">,</span> <span class="mi">1000</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">logpdf</span><span class="p">(</span><span class="n">var_l</span><span class="p">)</span>

    <span class="c1"># log likelihood</span>
    <span class="n">log_likelihood</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="o">-</span><span class="mf">0.5</span><span class="o">*</span><span class="n">y_train</span><span class="o">.</span><span class="n">T</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">inv_K</span><span class="p">)</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">y_train</span><span class="p">)</span> <span class="o">+</span> <span class="o">-</span><span class="mf">0.5</span><span class="o">*</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">model</span><span class="o">.</span><span class="n">K</span><span class="p">))</span> <span class="o">+</span> <span class="n">prior</span>

    <span class="k">return</span> <span class="n">log_likelihood</span> <span class="o">+</span> <span class="n">prior</span>

<span class="c1"># the trace of the sampler</span>
<span class="n">trace</span> <span class="o">=</span> <span class="p">{</span>
    <span class="s1">&#39;c&#39;</span> <span class="p">:</span> <span class="p">[</span><span class="mf">0.0</span><span class="p">],</span>
    <span class="s1">&#39;var_b&#39;</span> <span class="p">:</span> <span class="p">[</span><span class="mi">69</span><span class="o">**</span><span class="mi">2</span><span class="p">],</span>
    <span class="s1">&#39;var_k&#39;</span> <span class="p">:</span> <span class="p">[</span><span class="mi">388</span><span class="o">**</span><span class="mi">2</span><span class="p">],</span>
    <span class="s1">&#39;var_l&#39;</span> <span class="p">:</span> <span class="p">[</span><span class="mi">172</span><span class="o">**</span><span class="mi">2</span><span class="p">],</span>
<span class="p">}</span>

<span class="c1"># take jsut enough samples to make the point</span>
<span class="n">n_iter</span> <span class="o">=</span> <span class="mi">100</span>

<span class="c1"># simple metropolis sampler</span>
<span class="n">progress</span> <span class="o">=</span> <span class="n">progressbar</span><span class="o">.</span><span class="n">ProgressBar</span><span class="p">()</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="n">progress</span><span class="p">(</span><span class="nb">range</span><span class="p">(</span><span class="n">n_iter</span><span class="p">)):</span>

    <span class="c1"># c step</span>

    <span class="n">propose_c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">trace</span><span class="p">[</span><span class="s1">&#39;c&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mf">100.0</span><span class="p">)</span>

    <span class="n">propose_ll</span> <span class="o">=</span> <span class="n">log_likelihood</span><span class="p">(</span><span class="n">propose_c</span><span class="p">,</span>
                                <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;var_b&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                                <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;var_k&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                                <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;var_l&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

    <span class="n">current_ll</span> <span class="o">=</span> <span class="n">log_likelihood</span><span class="p">(</span><span class="n">trace</span><span class="p">[</span><span class="s1">&#39;c&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                                <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;var_b&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                                <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;var_k&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                                <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;var_l&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

    <span class="k">if</span> <span class="n">propose_ll</span> <span class="o">-</span> <span class="n">current_ll</span> <span class="o">&gt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)):</span>
        <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;c&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">propose_c</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;c&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">trace</span><span class="p">[</span><span class="s1">&#39;c&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

    <span class="c1"># var_b step</span>

    <span class="n">propose_var_b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">trace</span><span class="p">[</span><span class="s1">&#39;var_b&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mf">1000.0</span><span class="p">)</span>

    <span class="n">propose_ll</span> <span class="o">=</span> <span class="n">log_likelihood</span><span class="p">(</span><span class="n">trace</span><span class="p">[</span><span class="s1">&#39;c&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                                <span class="n">propose_var_b</span><span class="p">,</span>
                                <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;var_k&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                                <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;var_l&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

    <span class="n">current_ll</span> <span class="o">=</span> <span class="n">log_likelihood</span><span class="p">(</span><span class="n">trace</span><span class="p">[</span><span class="s1">&#39;c&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                                <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;var_b&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                                <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;var_k&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                                <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;var_l&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

    <span class="k">if</span> <span class="n">propose_ll</span> <span class="o">-</span> <span class="n">current_ll</span> <span class="o">&gt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)):</span>
        <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;var_b&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">propose_var_b</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;var_b&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">trace</span><span class="p">[</span><span class="s1">&#39;var_b&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

    <span class="c1"># var_k step</span>

    <span class="n">propose_var_k</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">trace</span><span class="p">[</span><span class="s1">&#39;var_k&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mf">1000.0</span><span class="p">)</span>

    <span class="n">propose_ll</span> <span class="o">=</span> <span class="n">log_likelihood</span><span class="p">(</span><span class="n">trace</span><span class="p">[</span><span class="s1">&#39;c&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                                <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;var_b&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                                <span class="n">propose_var_k</span><span class="p">,</span>
                                <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;var_l&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

    <span class="n">current_ll</span> <span class="o">=</span> <span class="n">log_likelihood</span><span class="p">(</span><span class="n">trace</span><span class="p">[</span><span class="s1">&#39;c&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                                <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;var_b&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                                <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;var_k&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                                <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;var_l&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

    <span class="k">if</span> <span class="n">propose_ll</span> <span class="o">-</span> <span class="n">current_ll</span> <span class="o">&gt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)):</span>
        <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;var_k&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">propose_var_k</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;var_k&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">trace</span><span class="p">[</span><span class="s1">&#39;var_k&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

    <span class="c1"># var_l step</span>

    <span class="n">propose_var_l</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">trace</span><span class="p">[</span><span class="s1">&#39;var_l&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span> <span class="mf">1000.0</span><span class="p">)</span>

    <span class="n">propose_ll</span> <span class="o">=</span> <span class="n">log_likelihood</span><span class="p">(</span><span class="n">trace</span><span class="p">[</span><span class="s1">&#39;c&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                                <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;var_b&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                                <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;var_k&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                                <span class="n">propose_var_l</span><span class="p">)</span>

    <span class="n">current_ll</span> <span class="o">=</span> <span class="n">log_likelihood</span><span class="p">(</span><span class="n">trace</span><span class="p">[</span><span class="s1">&#39;c&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                                <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;var_b&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                                <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;var_k&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">],</span>
                                <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;var_l&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

    <span class="k">if</span> <span class="n">propose_ll</span> <span class="o">-</span> <span class="n">current_ll</span> <span class="o">&gt;=</span> <span class="n">np</span><span class="o">.</span><span class="n">log</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">uniform</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">1</span><span class="p">,</span> <span class="mi">1</span><span class="p">)):</span>
        <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;var_l&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">propose_var_l</span><span class="p">)</span>
    <span class="k">else</span><span class="p">:</span>
        <span class="n">trace</span><span class="p">[</span><span class="s1">&#39;var_l&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">append</span><span class="p">(</span><span class="n">trace</span><span class="p">[</span><span class="s1">&#39;var_l&#39;</span><span class="p">][</span><span class="o">-</span><span class="mi">1</span><span class="p">])</span>

</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area stderr docutils container">
<div class="highlight"><pre>
100% |########################################################################|
</pre></div></div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[14]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">10</span><span class="p">,</span><span class="mi">4</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">suptitle</span><span class="p">(</span><span class="s2">&quot;Posterior Over Kernel Parameters (Trace Plots)&quot;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">141</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">trace</span><span class="p">[</span><span class="s1">&#39;c&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">142</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">trace</span><span class="p">[</span><span class="s1">&#39;var_b&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">143</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">trace</span><span class="p">[</span><span class="s1">&#39;var_k&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">subplot</span><span class="p">(</span><span class="mi">144</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">hist</span><span class="p">(</span><span class="n">trace</span><span class="p">[</span><span class="s1">&#39;var_l&#39;</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/markdown_examples_Fitting_A_GP_11_0.png" src="../../_images/markdown_examples_Fitting_A_GP_11_0.png" />
</div>
</div>
<div class="nbinput docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[9]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span><span class="n">c</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">trace</span><span class="p">[</span><span class="s1">&#39;c&#39;</span><span class="p">])</span>
<span class="n">var_b</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">trace</span><span class="p">[</span><span class="s1">&#39;var_b&#39;</span><span class="p">])</span>
<span class="n">var_k</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">trace</span><span class="p">[</span><span class="s1">&#39;var_k&#39;</span><span class="p">])</span>
<span class="n">var_l</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">trace</span><span class="p">[</span><span class="s1">&#39;var_l&#39;</span><span class="p">])</span>

<span class="c1"># definine a GP based on optimal parameters</span>
<span class="n">d</span> <span class="o">=</span> <span class="n">distance</span><span class="o">.</span><span class="n">Linear</span><span class="p">(</span><span class="n">c</span><span class="p">,</span> <span class="n">var_b</span><span class="p">,</span> <span class="n">var_k</span><span class="p">)</span>
<span class="n">kernel</span> <span class="o">=</span> <span class="n">kernel_base</span><span class="o">.</span><span class="n">Kernel</span><span class="p">(</span><span class="n">d</span><span class="p">,</span> <span class="s1">&#39;k1&#39;</span><span class="p">)</span>
<span class="n">model</span> <span class="o">=</span> <span class="n">gpr</span><span class="o">.</span><span class="n">GaussianProcessInversion</span><span class="p">(</span><span class="n">kernel</span><span class="o">=</span><span class="n">kernel</span><span class="p">,</span> <span class="n">var_l</span><span class="o">=</span><span class="n">var_l</span><span class="p">,</span> <span class="n">show_warnings</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span> <span class="n">y_train</span><span class="p">)</span>

<span class="c1"># generate data to plot posterior of model</span>
<span class="n">x</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">linspace</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span><span class="mi">15</span><span class="p">,</span><span class="mi">100</span><span class="p">)</span>

<span class="c1"># pull the parameters of the posterior distribution</span>
<span class="n">mean</span><span class="p">,</span> <span class="n">var</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">posterior_predict</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

<span class="c1"># plot posterior of model</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span><span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;GP Posterior Distribution&quot;</span><span class="p">)</span>
<span class="n">gp_viz</span><span class="o">.</span><span class="n">regression</span><span class="o">.</span><span class="n">plot_1d</span><span class="p">(</span><span class="n">x</span><span class="p">,</span><span class="n">mean</span><span class="p">,</span><span class="n">var</span><span class="p">[:,</span><span class="mi">0</span><span class="p">])</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train Data&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;c&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Test Data&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>

<span class="c1"># plot posterior predictive</span>
<span class="n">plt</span><span class="o">.</span><span class="n">figure</span><span class="p">(</span><span class="n">figsize</span><span class="o">=</span><span class="p">(</span><span class="mi">20</span><span class="p">,</span> <span class="mi">5</span><span class="p">))</span>
<span class="n">plt</span><span class="o">.</span><span class="n">title</span><span class="p">(</span><span class="s2">&quot;GP Posterior Predictive&quot;</span><span class="p">)</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">3</span><span class="p">):</span>

    <span class="c1"># draw a sample from the posterior</span>
    <span class="n">posterior_sample</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">posterior_sample</span><span class="p">(</span><span class="n">x</span><span class="p">)</span>

    <span class="c1"># add likelihood noise</span>
    <span class="n">liklihood_noise</span> <span class="o">=</span> <span class="n">model</span><span class="o">.</span><span class="n">var_l</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">samples</span><span class="p">)</span>
    <span class="n">liklihood_noise</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">diag</span><span class="p">(</span><span class="n">liklihood_noise</span><span class="p">)</span>
    <span class="n">posterior_predictive_sample</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">multivariate_normal</span><span class="p">(</span><span class="n">mean</span><span class="o">=</span><span class="n">posterior_sample</span><span class="p">,</span> <span class="n">cov</span><span class="o">=</span><span class="n">liklihood_noise</span><span class="p">,</span> <span class="n">size</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span>

    <span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x</span><span class="p">,</span> <span class="n">posterior_predictive_sample</span><span class="p">,</span> <span class="n">label</span><span class="o">=</span><span class="s2">&quot;GP Posterior Predictive Sample&quot;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;k&#39;</span><span class="p">,</span> <span class="n">alpha</span><span class="o">=</span><span class="mf">0.3</span><span class="p">)</span>

<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_train</span><span class="p">,</span><span class="n">y_train</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Train Data&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;c&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">scatter</span><span class="p">(</span><span class="n">x_test</span><span class="p">,</span><span class="n">y_test</span><span class="p">,</span><span class="n">label</span><span class="o">=</span><span class="s1">&#39;Test Data&#39;</span><span class="p">,</span> <span class="n">c</span><span class="o">=</span><span class="s1">&#39;r&#39;</span><span class="p">)</span>
<span class="n">plt</span><span class="o">.</span><span class="n">legend</span><span class="p">()</span>
<span class="n">plt</span><span class="o">.</span><span class="n">show</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="nboutput docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/markdown_examples_Fitting_A_GP_12_0.png" src="../../_images/markdown_examples_Fitting_A_GP_12_0.png" />
</div>
</div>
<div class="nboutput nblast docutils container">
<div class="prompt empty docutils container">
</div>
<div class="output_area docutils container">
<img alt="../../_images/markdown_examples_Fitting_A_GP_12_1.png" src="../../_images/markdown_examples_Fitting_A_GP_12_1.png" />
</div>
</div>
<div class="nbinput nblast docutils container">
<div class="prompt highlight-none notranslate"><div class="highlight"><pre><span></span>[ ]:
</pre></div>
</div>
<div class="input_area highlight-ipython3 notranslate"><div class="highlight"><pre>
<span></span>
</pre></div>
</div>
</div>
</div>
</div>


           </div>
           
          </div>
          <footer>
  
    <div class="rst-footer-buttons" role="navigation" aria-label="footer navigation">
      
      
        <a href="Intro_To_GP.html" class="btn btn-neutral float-left" title="An Introduction to Gaussian Processes Models" accesskey="p" rel="prev"><span class="fa fa-arrow-circle-left"></span> Previous</a>
      
    </div>
  

  <hr/>

  <div role="contentinfo">
    <p>
        &copy; Copyright 2019, James Montgomery

    </p>
  </div>
  Built with <a href="http://sphinx-doc.org/">Sphinx</a> using a <a href="https://github.com/rtfd/sphinx_rtd_theme">theme</a> provided by <a href="https://readthedocs.org">Read the Docs</a>. 

</footer>

        </div>
      </div>

    </section>

  </div>
  


  <script type="text/javascript">
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script>

  
  
    
   

</body>
</html>